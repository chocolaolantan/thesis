卒業研究 chocolaolantan/Thesis
# word2vecにより獲得した形態素意味表現の利用に関する実験

## 1. 概要
日本語版Wikipedia記事をword2vecで処理して得られた意味表現を使って**何か**したい。

## 2. [word2vec](https://github.com/svn2github/word2vec)とは
2013年にGoogleが公開した自然言語処理のプロジェクトで、分かち書きされた形態素を入力とし、各形態素の分散的意味表現を学習するツールである。

## 3. 情報科学における自然言語処理
昨今、インターネット・コンピュータの急速な普及に伴い、電子メールやチャットなど、従来紙や音声で表現されていたものを含め、多くの文書がテキストデータとして計算機（コンピュータ）で利用できるようになった。  
このテキスト情報が膨大なものになっていくことで、どのようにして有用な情報を抽出するか、また、計算機でどのようにテキストを認識し、ユーザに応答するか、といった研究が盛んになっている。  
情報科学における自然言語処理研究にも様々な分野があるが、例えば

- 自動文書要約
- テキスト圧縮
- 文書検索
- 情報抽出
- 質問応答
- 文章生成
- 自動翻訳
- テキストマイニング
- 文書分類
- 感情分析

などがある。word2vecは、こういった技術の素地として、自然言語において意味を持つ最小の単位である形態素の意味を、数値表現した試みの一つである。話題になった特徴というのが、単語の演算を、ある程度高い精度で行うことができるからであった。  
「king – man + woman」を獲得したベクトルで演算してみると、「queen」が出てくるといった具合だ。

## 4. 単語を表現する
計算機により自然言語を処理することを考えた時、単語の文字自体は記号であり、意味を持たず処理することができない。そこで、単語を何らかの数値で表すのだが、単語自体は数値を持たないため、ラベル付けして表すことが多かった。例えば、100万単語あったなら100万次元のベクトルを用意して、各要素をそれぞれの単語に割り当てていた。こうした表現は**分布表現**と呼ばれている。

分布表現にもいくつか種類があり、ある単語に対応する次元の数値だけを１とする**one-hotベクトル**や、ある単語と他の単語が同じ文書、あるいは文に登場した頻度（共起頻度）を各要素の数値とした**共起頻度ベクトル**などがある。

しかし、こうした表現ではある単語のみ、あるいは共起語同士のみの関係しか見えず、また、未知語や新しい単語を追加する度にベクトルの次元を増やさねばならなくなる。

そこで、共起語以外の単語との関係性まで見えるほど表現豊かで、単語同士の演算処理まで出来るような固定次元のベクトル表現を目指すようになった。こうした考えのもと獲得した表現が**分散表現**である。

## 5. word2vec
先に述べたとおりに、word2vecは形態素の分散的意味表現を学習するツールであるが、一体どのように学習していくのか、その基本的な考え方を見ていく。

### 5.1. 単語の意味に関する２つの考え方
- 分布仮設(Distributional Hypothesis)
> The Distributional Hypothesis is that words that occur in the same contexts tend to have similar meanings.  
(Harris, 1954) (ACL wiki)

  "分布仮説とは、同じ文脈に現れた単語は、似たような意味を持つ。というものである。"

- 統計的意味論(Statistical Semantics)
> Statistical Semantics is the study of “how the statistical patterns of human word usage can be used to figure out what people mean, at least to a level sufficient for information access”  
(ACL wiki)

  "統計的意味論は、「人間の単語使用の統計パターンが、人々が何を意味するかを少なくとも情報アクセスに十分なレベルまで、理解するためにどのように使用できるか」の研究である"

単語の意味とはどのように決定されるか、認識できるか。我々は、未知語に出会った時も前後の文脈(単語の並び)であったり、どういった単語らと共に出現するかといった情報から意味を推測することができる。また、ある単語が出てきたから、次は、こういった単語が出てくるはずだと想像することができるために、誤字や脱字を判定することができるのだ。

word2vecの意味表現学習にも、言葉の、こうした性質を利用している。次に、その学習手法を紹介していく。

### 5.2. Continuous Bag-of-Words
一つが、連続Bag-of-Wordsモデルと呼ばれるものである。  
これは**与えられた文脈中の単語から、対象単語が出現する条件付き確率を最大化**する表現を学習するものである。

### 5.3. Continuous Skip-gram
もう一つが、連続Skip-gramモデルと呼ばれるものである。
これは**対象単語から周辺単語の出現予測のエラー率を最小化**する表現を学習するものである。

### 5.4. 内部
それぞれの学習方法で、コーパス中の各単語に、予めランダムな実数値で初期化した固定次元のベクトルを二本与えて、ソフトマックス関数により出現確率を求めている。
