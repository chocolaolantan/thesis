\chapter{関連研究}
本章では，本研究の中で用いる各要素技術の基になった，各関連研究について説明する．
文書を話題毎に分割するテキストセグメンテーションについて説明し，
その後語彙の結束性を重要文の選定に取り入れた，
本研究の先行研究である\cite{yotsutani}\cite{ohshima}の重要文抽出システムについて論じる．
最後に，文書の主張の内容を表すキーワードの抽出手法であるKeyGraph\cite{keygraph}について説明する．


\section{テキストセグメンテーション}
膨大な情報の流通を背景とした，情報検索，文書要約，文書分類などに
代表される文書処理が研究されている．
しかし，これら複数の話題を含む文書に対して，これらの処理を文書全体に施す場合には，
必ずしも十分な精度を得られるとは限らない．
この原因の一つとして，文書中の話題を特定したうえで処理を実行していないことが挙げられる．

このような問題を解決する技術として文書を意味的なまとまりで分割する
テキストセグメンテーション技術が研究されている．
文書を話題ごとのまとまり（セグメント）の集合として考えることで，
情報検索・文書要約・文書分類などの文書処理技術の精度向上が期待できる．
また，文書処理構造の解析や文書の可読性の向上などの幅広い応用も期待できる\cite{tt}．
このように文書処理の基盤技術としてテキストセグメンテーションは重要な技術である．

一般に，論文やマニュアルなどの長い文書であれば，章や節などにより文書は構造化されている場合が多い．
ここで，話題の粒度を荒く考えた場合には章や節が話題を表す単位であると考えることが可能である．
しかし，話題の粒度を細かく考えた場合には，章や節の中にも，複数の話題が存在する．
同様に，短い文書では，話題の粒度を荒く考えた場合には，１文書に対して１話題であると考えられるが，
話題の粒度を細かく考えた場合には，短い文書にも複数の話題が存在すると考えられる．
このように文書における話題を議論する際には，その粒度を考慮する必要がある．
文書における話題構造を理解することは様々な文書処理技術に有効なことであるが，
そのためには，粒度の荒い話題だけでなく，粒度の細かい話題も考慮する必要がある．
そこで，先に述べた大きな文書内における章や節の内部や短い文書に存在する
粒度の細かい話題を認定することを目的としたテキストセグメンテーションについて概略を説明し，
分割型手法の一つであるTextTiling法について説明する\cite{tt}\cite{hearst}．

\subsection{文書分割手法}
文書に複数の話題が存在する場合，
文書中の各話題に対応して意味的つながりを持った語の連鎖である語彙的連鎖が存在する．
語彙的連鎖を認定し，各語彙的連鎖ごとに文書を分割することがテキストセグメンテーションである．
テキストセグメンテーションの手法としては，以下に示す併合型・分割型の２種の手法が存在する．

\begin{description}
  \item[併合型] 文書内の文や単語を最小単位とし，隣接する単位を併合する手法
  \item[分割型] 分割されていない文書から話題分割のための境界を探索する手法
\end{description}

併合型の手法としては，重要語の続く隣接単位を連結する手法が提案されている\cite{nishizawa}．
分割型の手法としては，以下に示す手法を提案されている．

\begin{itemize}
  \item シソーラス上での類義語が連続して出現する部分を語彙的連鎖として捉え，その開始位置，終了位置，連鎖の出現しないギャップの位置にスコアを与え，連鎖の出現しないギャップの位置にスコアを与え，その総和より話題の境界を推定する手法\cite{honda}
  \item シソーラス上の類義語が連続している部分を語彙的連鎖として捉え，さらに接続詞，助詞などの表層情報を組み合わせて話題の境界を推定する手法\cite{mochiduki}
  \item テキスト中のある基準点に対して左右同数の単語を含む窓を設け，左右の窓の類似度が高い部分を語彙的連鎖とみなし，類似度が極小となる基準点を話題の境界とするText\ Tiling法
\end{itemize}

テキストセグメンテーションに求められる条件として，
文書に設ける話題数を実際の話題数と同等かそれ以下に設定することが挙げられる．
これは，文書に含まれている話題数より多くの話題へセグメントした場合には，
高い再現率を得ることはできるが，
これではテキストセグメンテーションそもそもの目的から大きくはずれていることがわかる．
短い文書では，実際の話題数を超えて多くの話題を設けた場合には優位な語彙的連鎖が切断されるため，
文書に設けた各話題が意味的なまとまりを表さない．
すなわち，テキストセグメンテーションの出力数を考慮せずに再現率を重視することは
適切でないということである．
併合型の手法には，再現率が適合率を上回るため，上の要請を満たさない．
分割型手法の中で，Text\ Tiling手法は前提条件を満たすが，
長い文書を対象とした手法であり，短い文書を対象とせいた場合には十分な精度が得られるとは限らない．
以下Text\ Tiling法とその問題点を説明する．

\subsection{Text\ Tiling法とその問題点}
Text\ Tiling法では，文書の意味的に関連の深い部分には同一の語が繰り返し出現する
という性質を利用している．
文書中のある基準点に対してその左右に同数の単語を包含した窓を設け，
左右の窓の類似度（結束度）を求め，基準点を一定間隔でずらしながら類似度の変化に着目し，
グラフにおける類似度の極小点を話題の境界と推定する手法をとっている．
窓間の類似度は，次に示すcosine\ measureで表される．
\begin{eqnarray}
\label{tt_sim}
sim(wl,wr)=\frac{\sum _{t}f(t_{wl})f(t_{wr})}{\sqrt{\sum _{t}f(t_{wl})^{2}\sum _{t}f(t_{wr})^{2}}}
\end{eqnarray}
ここで，wlとwrはそれぞれ左窓と右窓であり，$f(t_{wl}$ と $f(t_{wr}$ は，
それぞれ，単語tの左窓，右窓における出現頻度である．

% 図の挿入
\begin{figure}[htb]
  \begin{center}
    \includegraphics[keepaspectratio=true,height=50mm]{clip004.eps}
  \end{center}
  \caption{Text Tiling法}
  \label{fig:clip004.eps}
\end{figure}


図\ref{fig:clip004.eps}の例において，文書の３文目と４文目の境界を基準点として窓が包含する単語数を９とすると，基準点に対する左右の窓における各単語の（Ａ〜Ｆ）の出現頻度は，以下に示すようになる．
\begin{eqnarray*}
f(A_{wl})=2,f(A_{wr})=1\\
f(B_{wl})=2,f(B_{wr})=2\\
f(C_{wl})=1,f(C_{wr})=3\\
f(D_{wl})=1,f(D_{wr})=0\\
f(E_{wl})=1,f(E_{wr})=2\\
f(F_{wl})=2,f(F_{wr})=1\\
\end{eqnarray*}
よって，式(\ref{tt_sim})を用いて類似度$sim(wl,wr)$は，以下のとおり計算される．
\begin{eqnarray}
sim(wl,wr)=\frac{2+4+3+0+2+2}{\sqrt{15\cdot 19}}=0.77
\end{eqnarray}

上述の手法を用いて，基準点を文書の先頭から末尾に向かって一定間隔で移動しながら，
各基準点における左右の窓の類似度をプロットすると
図\ref{fig:clip007.eps}に示すようなグラフになる．
ここで，類似度が極小値をとる基準点，すなわり，左右の窓の結束性が極小となる位置を話題の境界とする．

% 図の挿入
\begin{figure}[htb]
  \begin{center}
    \includegraphics[keepaspectratio=true,height=65mm]{clip007.eps}
  \end{center}
  \caption{Text Tiling法によるセグメンテーションの例}%{}内にタイトルを記入してください
  \label{fig:clip007.eps}
\end{figure}


ただし，類似度の微妙な揺れを無視するため，
極小点mpの類似度$S_{mp}$と左側の極大点lpにおける類似度$S_{lp}$，
右側の極大点rpにおける$S_{rp}$の差を考慮し，以下の式でdepth\ scoreを求め，
depth\ scoreがしきい値$d_{th}$を超えた場合に話題の境界とする．
$\bar{S}$は類似度の平均，$\sigma$ は類似度の分散を示す．
\begin{eqnarray}
depth\ score=(S_{lp}-S_{mp})+(S_{rp}-S_{mp})
\end{eqnarray}

\begin{eqnarray}
d_{th}=\bar{S}-\frac{\sigma}{2}
\end{eqnarray}


しかし，この手法には以下の２つの問題点がある．
\begin{enumerate}
  \item 窓が小さくなると，左右の窓における類似度が顕著に低くなるため，短い文書では左右の窓の正確な類似度が計算できない
  \item 文書の先頭，末尾付近では，左右同一数の単語数を包含する窓を設定できない．
\end{enumerate}

(1)について，左右の窓に含まれる単語数が数百以上であれば，
両窓に同一語が出現することが期待できる．
特にマニュアルや論文などの複数の章から構成される大きな文書を対象とした場合に有効である．
しかし短い文書では，小さな範囲内で同一の語が繰り返し出現することは稀である．
よって，短い文書を対象とする場合には設定できる窓幅が小さくなることもあり，
左右の窓の類似性はみられなっくなる場合が多くなる．
左右の窓の類似点が０となる基準点が多くなると語彙的連鎖があっても認定できないため，
テキストセグメンテーションの精度に悪影響を及ぼす．

(2)について，基準点に対して単純に左右に窓を設ける手法では，
文書の先頭付近では左側の窓，文書の末尾付近では右側の窓が包含する単語数が少なくなることができない．
上記の問題点は，特に短い文書では顕著に表れ，語彙的連鎖認定における大きな問題点となる．
次章で説明するが，この問題点を補うために文書内での語の共起を考慮する手法が提案されており\cite{hirao}，本研究においても用いている．


\section{PageRankモデル}
本研究で構築する要約モデルの中核となるPageRankモデルについて
関連研究と交えて論じる．

\subsection{PageRankアルゴリズムとは}
PageRankアルゴリズムとは
web検索エンジンGoogle\footnote{(日本語) http://www.google.co.jp/}のベース技術として用いられており，
「多くの良質なページからリンクされているページはやはり良質なページである．」
という再帰的な関係をもとに，全てのページの重要度を判定したものである． 
Googleから出されているPageRankの紹介ページ\footnotemark
\footnotetext{http://www.google.co.jp/intl/ja/why\_ use.html}では以下のように説明されている．
\begin{quote}
PageRankについて

『PageRankは，ウェブの膨大なリンク構造を用いて，その特性を生かします．
ページAからページBへのリンクをページAによるページBへの支持投票とみなし，
Googleはこの投票数によりそのページの重要性を判断します．
しかしGoogleは単に票数，つまりリンク数を見るだけではなく，
票を投じたページについても分析します．
「重要度」 の高いページによって投じられた票はより高く評価されて，
それを受け取ったページ を「重要なもの」にしていくのです．
 
こうした分析によって高評価を得た重要なページには高いPageRankが与えられ，
検索結果内の順位も高くなります．
PageRankは Googleにおけるページの重要度を示す総合的な指標であり，
各検索に影響されるものではありません．
むしろ，PageRankは複雑なアルゴリズムにしたがったリンク構造の分析にもとづく，
各ウェブページそのものの特性です． 

もちろん，重要度が高いページでも検索語句に関連がなければ意味がありません． 
そのためにGoogleは洗練されたテキストマッチ技術を使って，
検索に対し重要でなおかつ，的確なページを探し出します．』
\end{quote}

% 図の挿入

\begin{figure}[h]
  \begin{center}
    \includegraphics[keepaspectratio=true,height=80mm]{clip018.eps}
  \end{center}
  \caption{PageRankの概念図}%{}内にタイトルを記入してください
  \label{fig:clip018.eps}
\end{figure}

$PageRank$アルゴリズムでは，あるページ$P_1$からページ$P_2$への
リンクをページ$P_1$から$P_2$への指示投票とみなし，その票数から重要度を算出する．
このアルゴリズムを具体的に見ると Fig.\ref{fig:clip018.eps}のようになる．
あるページの PageRank を，そのページに存在する発リンク数で割った数が，
それぞれ被リンク先の PageRank に加算されるという関係になっている．

これまでにも，張られているリンク（$Back\; Link$）数を重要度とする方法は存在していたが，
$PageRank$アルゴリズムの特徴的な点は，リンク元であるページ$P_1$の重要度によって，
1票の重みが変わるということである．
ページ$P_1$が重要度の高いページであれば，1票の重みが増え，
それがページ$P_2$にも反映され，ページ$P_2$は重要度の高いページとなる．
しかしページ$P_1$の重要度が低いページであった場合，1票の重みが低くなるのでページ$P_2$は
重要度の低いページとなる．

具体的な$PageRank$アルゴリズムの計算方法を考えてみる．
もっとも基本的な考え方として，リンク関係を行列の形で表わしてみると，
あるページ$i$から別のページ$j$へリンクが張られている場合にはその成分を1とし，
そうでない場合を0とする．ここで考えたいのは，リンクが張られていれば隣接関係がある
ということであり，$Web$のリンク関係を有向グラフ$S$と見なし，その隣接行列$A$を求めたい．
行列$A$の成分$a_{ij}$は，

\begin{eqnarray}
a_{ij} = \left\{
  \begin{array}{ll}
    1   & if\ (ページ i からページ j へのリンクが「ある」場合)   \\
    0   & if\ (ページ i からページ j へのリンクが「ない」場合)   \\
  \end{array}
\right.
\end{eqnarray}



で表わされるとする．ページ数をNとするとこの行列は$N\times N$の$N$次正方行列になる．
PageRankを求めるための行列はこの隣接行列$A$を転置し，
さらにそれぞれの列ベクトルの総和が 1 （全確率）になるように
それぞれのリンク数（すなわち，非零要素数）で割ったものと言える．
この行列を「推移確率行列$M$」と呼び，$N$個の確率変数を持ち各行ベクトルは状態間の推移確率を表わす．

転置する理由は，$PageRank$が「どれだけリンクしているか」ではなく
「どれだけリンクされているか」を重視しているからである． 
PageRank の計算は，
この推移確率行列$M$の最大固有値に属する固有ベクトル(優固有ベクトル)を求めることになる．

% 図の挿入
\begin{figure}[h]
  \begin{center}
    \includegraphics[keepaspectratio=true,height=100mm]{clip019.eps}
  \end{center}
  \caption{ページ相互のリンク関係を表わした推移図}%{}内にタイトルを記入してください
  \label{fig:linkstruct.eps}
\end{figure}

具体例を用いて逐次的に$PageRank$を計算してみる．
Fig.\ref{fig:linkstruct.eps}のようなリンク関係を持つ
7つのHTML文書を考える．なお，この$HTML$文書間の
リンク関係は1-7の文書だけで閉じているものとする．
Table.\ref{suii_list}はそれぞれのリンク元IDから
発するリンク先IDを列挙したものである．

% 表の挿入
\begin{table}[h]
 \caption{推移リストの配列表現}% {}内に表題を書く
 \label{suii_list}
 \begin{center}
  \begin{tabular}{|c|c|}
    \hline
     リスト元$ID$  &  リンク先$ID$  \\
    \hline
      1 &  2,3,4,5,7  \\
    \hline
      2 &  1  \\
    \hline
      3 &  1,2 \\
    \hline
      4 &  2,3,5  \\
    \hline
      5 &  1,3,4,6  \\
    \hline
      6 &  1,5  \\
    \hline
      7 &  5  \\
    \hline
  \end{tabular}
 \end{center}
\end{table}

この隣接リストで表現されるリンク関係の隣接行列$A$は
式(\ref{rinsetsu_matrix})のような7$\times$7の
正方行列になる．
要素は0か1だけの行列を考える．$i$行目を横に見れば
「文書$i$からリンクしている文書$ID$」を
表わしていることになる．

\begin{equation}
\label{rinsetsu_matrix}
A=\left[
  \begin{array}{ccccccc}
    0   &  1  &  1  &  1  &  1  &  0  &  1  \\
    1   &  0  &  0  &  0  &  0  &  0  &  0  \\
    1   &  1  &  0  &  0  &  0  &  0  &  0  \\
    0   &  1  &  1  &  0  &  1  &  0  &  0  \\
    1   &  0  &  1  &  1  &  0  &  1  &  0  \\
    1   &  0  &  0  &  0  &  1  &  0  &  0  \\
    0   &  0  &  0  &  0  &  1  &  0  &  0  \\
  \end{array}
\right]
\end{equation}

式(\ref{suii_matrix})の推移確率行列$M$は，
$A$を転置しそれぞれの列を非零要素数で割った，
以下のような7$\times$7の正方行列になる．$i$行目の
非零要素を横に見れば「文書$i$に対してリンクを
張っている文書$ID$」を表わしていることになる．
各列を縦に足し合わせるとすべて1（全確率）
になっている．

\begin{equation}
\label{suii_matrix}
M=\left[
  \begin{array}{ccccccc}
    0       &  1  &  1/2  &  0      &  1/4  &  1/2  &  0  \\
    1/5   &  0  &  1/2  &  1/3  &  0      &  0      &  0  \\
    1/5   &  0  &  0      &  1/3  &  1/4  &  0      &  0  \\
    1/5   &  0  &  0      &  0      &  1/4  &  0      &  0  \\
    1/5   &  0  &  0      &  1/3  &  0      &  1/2  &  1  \\
    0       &  0  &  0      &  0      &  1/4  &  0      &  0  \\
    1/5   &  0  &  0      &  0      &  0      &  0      &  0  \\
  \end{array}
\right]
\end{equation}

$PageRank$のベクトル$R$（それぞれのページの
ランクを表わす数値の列）は，式(\ref{pagerank})
という関係で表現できる（$c$は定数）．
この場合，$R$は固有ベクトルに相当し，
$c$は対応する固有値の逆数に相当する．そこで，
$R$の組を得るためには，この正方行列$M$を固有値分解すれば
良いことになる．
\begin{equation}
\label{pagerank}
R=cMR
\end{equation}

ここで，推移確率行列$M$の最大固有値の絶対値が
1（$c=1$）になる\cite{markov}ことを利用して，
\begin{equation}
R=MR
\end{equation}

Pageらはさらに，「ユーザは，多くの場合は
現在のページに存在するリンクをたどって移動するが，
時々は全く無関係なページにジャンプする」
というブラウジングモデルを式(\ref{pagerank})
に取り入れて，次であらわされた式によりPageRankの計算を行っている．

\begin{eqnarray}
M^{\prime} = & & \left( 1-\alpha \right) M+\alpha \left[ {\frac{1}{N}}\right]_{N\times N}\\
R = & & M^{\prime} \times R \nonumber \\
 = & & \left( 1-\alpha \right)M\times R + \alpha \left[ \frac{1}{N}\right]_{N\times 1}
\end{eqnarray}

webのページの重みをPageRankアルゴリズムを使って行う場合，
通常$\alpha$は0.1〜0.2の間に設定ている．


\subsection{PageRankの応用}
四ツ谷\cite{yotsutani}はPageRankアルゴリズムを応用して，
物語文に対して重要文を抽出する研究を行った．
彼は以下の要請を満たすように要約システムを構築した．

\begin{description}
  \item[要請1]語の共起する数が多ければ多いほど伝播力は大きく，またその語の重要度が大きければ大きいほど伝播力は大きい．
  \item[要請2]文を構成する語が重要な語であるほど伝播力は大きい．
  \item[要請3]重要なセンテンスに支えられているセンテンスは重要である．
  \item[要請4]重要なセンテンスが支えるセンテンスは重要である．
  \item[要請5]一回の思考で文の重要度を決定するのではなく，更新を繰り返しながら最終的な重要度を決定する． 
\end{description}

このモデルは，文の中身に対する情報（ここでは単語情報）と
文と文の相互関係に関する情報の両方を取り入れた文の重要度の決定手法である．
まず，文と文の相互関係を調べるために文間で共起する語の種類と数，
格情報，階層の深さ情報を用いており，文間のリンク強度としている．
その文間のリンク構造と強度から推移確率行列を定義し，
PageRankを用いて文の重要度を計算した．
本研究でもこのモデルとPageRankアルゴリズムを利用し，重要文抽出を行う．


\section{KeyGraph}
本章では，KeyGraphは，文書の主張の内容を表すキーワードの抽出を
目指した手法であるKey\ Graph\cite{keygraph}について説明する．
本研究の中で，各話題間をつなぐ単語の抽出を行うが，
そのキーワード抽出手法の基としてKey Graph手法の考え方を利用した．

\subsection{キーワード抽出}
文書検索において，検索文書からキーワードを抽出しておくことは，
検索時間の短縮と，検索結果の質の向上の画面において重要であり，
そこから，文書の主張の内容を表すキーワードの抽出を目的とした手法である．
この目的に対しては，ユーザの興味に関連する既存分野を代表するものを選ぶ場合とは違い，
検索対象文書の著者独特の考えを把握する技術が必要となる．

そこでKeyGraphでは，文書は著者独特の考えを主張するために書かれており，
その考えを表すために内容が構成されるという仮定に基づき，
語の共起グラフの分割・結合操作によってキーワードを抽出する新しい手法を提案している．

従来の日常的に我々が用いているキーワードには，
\begin{enumerate}
  \item 文書に関連する既存分野名
  \item キーワードを示せと指示された著者が付けたもの
  \item 各文書に専門家が付けたキーワード
  \item テキストから自動的に抽出したキーワード
\end{enumerate}
などの数種類のものがある．

(1)は，文書の主張の内容を表すという目的からは外れている上に，
付けられた分野名は信頼性に欠けるという問題点がある．
該当分野を示そうとしても，高い新規性を有する文書などは既存の分野に収まりづらいことがあるためである．

(2)のように，著者がキーワードを示す場合には，該当分野を示すべきか，
自分の主張点を示すべきかの判断が委ねられており，また，文書量が膨大になることで，
(3)のように人手でキーワードを付加することは困難となる．
従って(4)のキーワードの自動抽出が不可欠な技術となる．

従来のキーワードの自動抽出手法としては，
\begin{enumerate}
  \item 文書の見出しを用いる方法
  \item 文書の冒頭からのキーワード抽出
  \item 自然言語解析を用いるキーワード抽出
  \item 統計量に基づくキーワード抽出
\end{enumerate}
がある．

(1)(2)は，文書のポイントを簡潔に要約したものとなっているものが多い\cite{nomoto}．
また新聞記事などの場合は，冒頭部に重要な語が多い（参考文献）ことを利用する手法であるが，
実際，文書の種類によって主要部分の位置は様々で，重要な意味の分類が少数の大段落に集中するとしても，それがどの段落であるかなどは筆者の章立てに依存している\cite{suzuki}．

(3)ように，自然言語解析によって文書中のどの語が重要であるか理解できるなら，
正確なキーワード抽出が実現できるかもしれない．
しかし，文法ルールに従うとは限らない文書から自然言語解析によって，
要点を的確に取り出すのは現時点では困難である．
また重要な語は太字で書かれているとか，前置きがあるなどということも一般には期待するのは難しい．

(4)は，古くからある手法で，対象文書中で頻出する語をキーワードとする手法がある\cite{cohen}．
しかし，頻出語が文書の独自な主張を表現する語になることは少ない．
実際に，頻出語は文書独自の主張点を表すのではなく，
ある一定の分野に読者を誘い込み理解の土台を確保する役割を果たすものである．
一方対象とする文書$D_{i}$の属する分野のコーパスを用いて，
ある語$T_{j}$の$D_{i}$での頻度$tf_{ij}$と，
その分野での平均出現頻度$df_{j}$に対する相対比率（TFIDFなど）を
語$T_{j}$の重要度とするアプローチがある．
この手法では，単に$D_{i}$での出現回数の多い語よりは重要な語を抽出できる．
あるいは，文書を正しく分類する効果の高い語を「分野」対「語」の相対情報量に基づいて，
学習しておき，これらのうち文書$D_{i}$に含まれているものを
キーワードとする手法も文書の分類に役立つ．
しかし，特定分野のコーパスは，その分野が不明では作ることができない，
逆に分野を限定しないコーパスは，集めるべき用例が多すぎて現実には構築できない．

\subsection{基本的な考え方}
KeyGraphは，文書は著者独自の考えを主張するために書かれるという仮説を基にしている．
文書全体はその主張を目指して一つの流れを形成するというわけで，文書を建物に例えている．

\begin{quote}
建物が立つには，土台（文書がもとにしている基本概念）が必要である．
壁（文書の構成に必要な説明部分），ドアや窓（詳細な記述），
さまざまな装飾（比喩や例，付加的な記述）もある．
しかし，建物の本質は日射や雨から住人を守る屋根（主張点）であって，
屋根を支えるめに柱（内容の主な展開）がある．
\end{quote}

ということになる．
例えば論文であれば，文書が論理的な鎖状に構成されているものも多い．
その中には，数式やその説明，例証などのまとまりがあるが，
その中での頻出語は要点とは別の，いわばその文書が書かれる上で
当然のように前提とされる「土台」の概念を表すことが多い．
これらの土台の上に立つ「柱」に支えられて，文書全体を束ね方向づけるのが主張「屋根」である．
この土台・屋根・柱を頼りにキーワードとして取り出すのがKeyGraphの基本戦略である．

アルゴリズムは次の３フェーズからなる．
\begin{description}
  \item[土台の形成] 文書形成の準備あるいは前提となる基本概念を土台とする
  \item[屋根の形成] 上で取り出した土台たちに強い力で支えられて文書を統合する語を屋根とする
  \item[キーワード抽出] 土台と屋根を結ぶ強い柱が多く集まった語をキーワードとする
\end{description}

\subsubsection{土台の形成}
文書Dを表す共起グラフGを生成する．
このフェーズではGを以下のノードと枝から生成する．
準備段階として，文書に含まれる語をキーワードの候補とする．
\footnote{出現回数と長さの極大に基づいて，熟語として候補に追加しておく，
また，形容詞，副詞などの取扱によって候補は変化する．}
これを$D_{terms}$と呼ぶ．$D_{terms}$は非冗長，
すなわち$D_{terms}={w_{1},w_{2},\cdots ,w_{l},}$とすると，
$i\neq j$なる任意の整数$i,j (1\le i,j\le l)$について，$w_{i}\neq w_{j}$とする．
\begin{description}
  \item[ノード] $D_{terms}$中のの語は，Dにおける出現回数によってソートされる．このソートでの上位M語からなる集合をHighFreqと呼び，始めにG中のノード群として与えておく．
\end{description}

HighFreq中の語は土台を形成する要素として用いられる．
というのは，土台すなわち基礎概念を表す語はＤ中で何度も用いられることが多いからである．

\begin{description}
  \item[枝（リンク）] HighFreq中で共起度の高い語の対をそれぞれ枝で結ぶ．ここで，語の対$(w_{i},w_{j})$のＤにおける共起度$co(w_{i},w_{j})$を次のように定義する．
\begin{eqnarray}
co(w_{i},w_{j})=\sum _{s\in D}|w_{i}|_{s}|w_{j}|_{s}
\end{eqnarray}
\end{description}

ここで，$|x|_{s}$は文ｓにおける要素xの出現回数で，
xが語の場合に，$|x|_{s}$は文s中の語xの出現回数である．

式(1)は，ある文sに出現した語$w_{i}$はs中全ての$w_{j}$と共起しているとみなした共起度を表す．
２語間の共起度の定義は相互情報量\cite{church}などが考えられるが，
そのためには出現する単語の総数の２乗に比例する記憶容量が必要である．
また，「独立に出現する場合に比べて」ではなく，
近くに現れる回数が多い語の対を選ぶほうが適切であると考えることができる．
HighFrea中の語の各対は，coの大きさによってソートされ，
上位$M-1$番目までの語対にG中で枝を張る．
これがG中のノードを冗長なリンクなしに結びあわせるための必要最小限の枝数だからである．

すなわち，Gが連結グラフであれば，$M-1$本の枝だけG中に存在することは，
Gが単結合であることと同値であり，
それはDが冗長さなしに内容が展開する文書としてグラフ化されることである図\ref{fig:clip008.eps}(a)．
しかし，図\ref{fig:clip008.eps}(b)のように複数のパスを通って語１から語３が辿られるならば，
語３と語４の関係の強さが土台$G_{a}$の内部の語同士の関係よりも弱いと見なせる．
そこで，上記のノードとcoの上位$M-1$本の枝からなるグラフGのうち，
自分以外の連結部分グラフに含まれない連結部分グラフ
\footnote{自分が含むどの２ノード間にもパスを持つGの部分グラフ}，
すなわち極大連結部分グラフを一つの土台とする．

この土台の抽出法は，一つの文は一貫した概念を表現し，
その概念をめぐって文中の語が関係し合うという仮説（語彙的連鎖）に立っている．
KeyGraphでは，この語彙的連鎖を用いて文書の土台をつかみ，
文書全体の流れにとって重要な主張を表すキーワードを抽出している．

% 図の挿入
\begin{figure}[htb]
  \begin{center}
    \includegraphics[keepaspectratio=true,height=50mm]{clip008.eps}
  \end{center}
  \caption{土台($G_{a}$と$G_{b}$)と屋根ｗ）}
  \label{fig:clip008.eps}
\end{figure}


\subsubsection{屋根の形成}
土台，すなわり文書の基礎となる概念は，
文書全体から見ると著者が主張しようとすることを導き出すために関連しあっている．
ここで目的に沿うキーワードは，先述の屋根として土台だちに強い力に
支えられて文書を統合する語でなくてはならない．

KeyGraphでは，語wが土台たちに支えられる力を$key(w)$で表す．
$key(w)$は０から１までの実数で，
「G中の全ての土台を著者が考慮しているときにwが用いられる」という条件付確率を定式化したものである．
まず，$key(w)$を構成する２関数は以下のように定義される．

\begin{eqnarray}
f(w,g)=\sum _{s\in D}|w|_{s}-|g-w|_{s}
\end{eqnarray}

\begin{eqnarray}
F(g)=\sum_{s\in D} \sum_{w\in s}|g-w|_{s} 
\end{eqnarray}

ここで，sとwをそれぞれ文と語を指す添字，$|g|_{s}$を土台gに含まれる語のs中の出現回数として

\begin{equation}
|g-w|_{s}=\left\{
  \begin{array}{cc}
    |g|_{s}-|w|_{s}   & if\  w\in g    \\
    |g|_{s}   & if\ w\notin g    \\
  \end{array}
\right.
\end{equation}

とする．

すなわち$f(w,g)$は語wと土台g中の語の共起度である．
式でwがgに含まれるときにwの出現回数をgの出現回数から引くのは，
wとg中のw以外の語との共起度を調べるためである．
$key(w)$は次のように定義する．

\begin{eqnarray}
key(w)=\left[\prod _{g} ^{bases}(1-\frac{f(w,g)}{F(g)})\right]
\end{eqnarray}

ここで，basesは土台の個数である．$f(w,g)/F(g)$はg中の語と共起する語がwである確率であり，
これを著者が土台gの表す概念を考慮しているときに語wを書く確率として用いている．
すなわち式の$key(w)$は

\begin{eqnarray}
probability(w|\bigcap _{g\subset G}g)
\end{eqnarray}

を表そうとしているのであり，式が論理的に

\begin{eqnarray}
probability(\bigcup _{g\subset G}(w|g))
\end{eqnarray}

と等価になることから，得た式である．
なお，それぞれの土台が互いに独立であるとする仮定をおいた．
これは土台，すなわち基礎となる概念は，
それ以上基礎的な他の概念から導かれるものではなく，互いに独立であるという仮定にあたる．
文書D中のkeyの上位をHighkeyと呼ぶ．Highkey中の語がGにまだ含まれていなければ，
新しいノードとしてGに加える．


\subsubsection{キーワード抽出}
KeyGraphで取り出すキーワード群はHighKeyそのものではない．
それは土台中の語でも，屋根に強く結びついている語は屋根を表現し，
文書Dを要約する上で重要だからである．
これらの語はkeyの値は小さいかもしれないが，HighKey中の語と同様に，
接する柱（土台と屋根を結ぶリンク）の強さの和では上位にランクされるものと考えられる．
そこで，HighKey中の語との間の柱の強さの和の大きさを最終的にキーワードとする．

HighKey中の語$w_{i}$と，いずれかの土台に含まれる語$w_{j}$を結ぶ柱の強さ$c(w_{i},w_{j})$は次の式で表す．
\begin{eqnarray}
c(w_{i},w{j})=\sum _{s\in D}|w_{i}|_{s}|w_{j}|_{s}
\end{eqnarray}
そして，G中のノードで，接する柱全てのcの和が上位の語をキーワードとする．
KeyGraphでは，この３つのフェーズによって，キーワードを抽出している．

