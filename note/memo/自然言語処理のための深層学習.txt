Title : 自然言語処理のための深層学習

1. 自然言語処理
  1.) ことば、とは
    - 人と人とのコミュニケーションに用いられる道具。
    - 文字、あるいは音の並びによって構成されている。
    - 文字の並びによって構成される単語、の並びによって文が構築される。
    ※最小単位として、形態素を用いることにする。
      * 形態素 ： 文字列が意味、或いは役割をもつ最小のまとまり

  2.) 言語モデル、とは
    - 日本語らしさを判定するものさしのようなもの
    - 多くの言語モデルでは確率が用いられる。

    らしさ。は明確にわけられるものではなく、また、現実問題として判別を間違うことも起こりうるが、正解、不正解を１，０であらわしたとして、間違えてしまった時の影響が大きくなる。そのため度合いであらわされることが望ましい。
    度合いが表現できるならなんでもいいわけだが、確率を用いるのは、0-1でわかりやすく、扱いやすいということに加え、確率を用いると、ベイズの公式など種々の確率論により、応用が広がるという利点がある。
    例) 音響モデル

  3.) 言語処理の手法
    - ルールベース型
      人手で辞書や文法などのルールを制定し、それに基づいた処理をさせる手法
    - 統計的手法
      大量のテキストデータから、単語の出現率や共起度を算出し、確率的モデルを獲得する

2. TF-IDF(Term Frequency - Inverse Document Frequency)
  文書に含まれる単語の特徴の強さを表す数値。
  情報検索や文書推薦などによく用いられる。
  注意点として、値は母集団に多きな影響を受ける。



  - Term Frequency : 文書中における単語の出現頻度。文書を構成する単語総数に対して、注目単語が占める割合。
  - Document Frequency : 文書グループ全体を通した単語の出現頻度。文書総数に対して、注目単語を含む文書数が占める割合。
  - Inverse Document Frequency : DFの対数。文書集合の規模に対して、値の変化を小さくするために対数を取っている。

  TF-IDF = (文書1における単語Aの個数)÷(文書1を構成する単語の総数)×log(1÷((単語Aが出現した文書数)÷(文書の総数)))
        = (文書1における単語Aの個数)÷(文書1を構成する単語の総数)×log((文書総数)÷(単語Aが出現した文書数))
